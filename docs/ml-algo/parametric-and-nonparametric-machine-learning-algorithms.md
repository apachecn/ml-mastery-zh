# 参数化和非参数机器学习算法

> 原文： [https://machinelearningmastery.com/parametric-and-nonparametric-machine-learning-algorithms/](https://machinelearningmastery.com/parametric-and-nonparametric-machine-learning-algorithms/)

什么是参数化机器学习算法？它与非参数机器学习算法有什么不同？

在这篇文章中，您将发现参数和非参数机器学习算法之间的区别。

让我们开始吧。

![Parametric and Nonparametric Machine Learning Algorithms](img/b326598ff8e5e20a2984032cbe165115.jpg)

参数和非参数机器学习算法
照片由 [John M.](https://www.flickr.com/photos/luxxeon/8251183362) 拍摄，保留一些权利。

## 学习功能

机器学习可以概括为学习将输入变量（X）映射到输出变量（Y）的函数（f）。

Y = f（x）

算法从训练数据中学习该目标映射函数。

函数的形式是未知的，因此我们作为机器学习从业者的工作是评估不同的机器学习算法，并看看哪个更接近基础函数。

不同的算法对函数的形式以及如何学习它们做出不同的假设或偏见。

## 获取免费算法思维导图

![Machine Learning Algorithms Mind Map](img/2ce1275c2a1cac30a9f4eea6edd42d61.jpg)

方便的机器学习算法思维导图的样本。

我已经创建了一个由类型组织的60多种算法的方便思维导图。

下载，打印并使用它。

## 参数化机器学习算法

假设可以大大简化学习过程，但也可以限制可以学习的内容。将函数简化为已知形式的算法称为参数机器学习算法。

> 用一组固定大小的参数（与训练样本的数量无关）总结数据的学习模型称为参数模型。无论您在参数模型中投放多少数据，它都不会改变它所需要的参数数量。

- [人工智能：现代方法](http://www.amazon.com/dp/0136042597?tag=inspiredalgor-20)，第737页

算法包括两个步骤：

1.  选择功能的表单。
2.  从训练数据中学习函数的系数。

映射函数易于理解的函数形式是一条线，如线性回归中所使用的那样：

b0 + b1 * x1 + b2 * x2 = 0

其中b0，b1和b2是控制截距和斜率的线的系数，x1和x2是两个输入变量。

假设一条线的功能形式大大简化了学习过程。现在，我们需要做的就是估计线方程的系数，我们有一个问题的预测模型。

假设的函数形式通常是输入变量的线性组合，因此参数机器学习算法通常也称为“_线性机器学习算法_”。

问题是，实际的未知基础函数可能不是像线一样的线性函数。它可能几乎是一条线，需要对输入数据进行一些小的转换才能正常工作。或者它可能就像一条线，在这种情况下，假设是错误的，并且该方法将产生不良结果。

参数机器学习算法的更多示例包括：

*   Logistic回归
*   线性判别分析
*   感知
*   朴素贝叶斯
*   简单神经网络

参数化机器学习算法的好处：

*   **更简单**：这些方法更容易理解和解释结果。
*   **速度**：参数模型可以非常快速地从数据中学习。
*   **较少的数据**：它们不需要那么多的训练数据，即使数据的拟合不完美也能很好地工作。

参数化机器学习算法的局限性：

*   **约束**：通过选择函数形式，这些方法高度受限于指定的形式。
*   **有限复杂度**：这些方法更适合于更简单的问题。
*   **不合适**：实际上，这些方法不太可能与底层映射函数匹配。

## 非参数机器学习算法

不对映射函数的形式做出强有力假设的算法称为非参数机器学习算法。通过不做出假设，他们可以自由地从训练数据中学习任何功能形式。

> 如果您拥有大量数据且没有先验知识，并且您不想过于担心选择正确的功能，那么非参数方法就很好。

- [人工智能：现代方法](http://www.amazon.com/dp/0136042597?tag=inspiredalgor-20)，第757页

非参数方法寻求最佳地拟合训练数据以构建映射函数，同时保持一些推广到看不见的数据的能力。因此，它们能够适合大量的功能形式。

一个易于理解的非参数模型是k-最近邻算法，它基于新数据实例的k个最相似的训练模式进行预测。除了关闭的模式可能具有类似的输出变量之外，该方法不假设任何关于映射函数的形式。

流行的非参数机器学习算法的更多示例是：

*   k-最近邻居
*   决策树如CART和C4.5
*   支持向量机

非参数机器学习算法的好处：

*   **灵活性**：能够装入大量功能形式。
*   **权力**：没有关于基础功能的假设（或弱假设）。
*   **表现**：可以产生更高表现的预测模型。

非参数机器学习算法的局限性：

*   **更多数据**：需要更多训练数据来估计映射函数。
*   **较慢**：训练要慢很多，因为它们通常有更多的训练参数。
*   **过度拟合**：过度拟合训练数据的风险更大，并且更难解释为什么要进行特定预测。

## 进一步阅读

如果您希望了解有关参数和非参数机器学习算法之间差异的更多信息，本节列出了一些资源。

### 图书

*   [统计学习简介：在R](http://www.amazon.com/dp/1461471370?tag=inspiredalgor-20) 中的应用，第2章
*   [人工智能：现代方法](http://www.amazon.com/dp/0136042597?tag=inspiredalgor-20)，第18章

### 帖子

*   [在机器学习中使用非参数方法有什么好处？ Quora上的](https://www.quora.com/What-are-the-advantages-of-using-non-parametric-methods-in-machine-learning)
*   [非参数方法在机器学习中有哪些缺点？ Quora上的](https://www.quora.com/What-are-the-disadvantages-of-non-parametric-methods-in-machine-learning)
*   维基百科上的[非参数统计](https://en.wikipedia.org/wiki/Nonparametric_statistics)
*   维基百科上的[参数统计](https://en.wikipedia.org/wiki/Parametric_statistics)
*   堆栈交换上的[参数与非参数](http://stats.stackexchange.com/questions/50141/parametric-vs-nonparametric)

## 摘要

在这篇文章中，您已经发现了参数和非参数机器学习算法之间的区别。

您了解到参数化方法对输入变量到输出变量的映射做出了很大的假设，反过来训练速度更快，需要更少的数据但可能不那么强大。

您还了解到非参数方法对目标函数做出很少或没有假设，反过来又需要更多数据，训练速度较慢，模型复杂度较高，但可以产生更强大的模型。

如果您对参数或非参数机器学习算法或本文有任何疑问，请发表评论，我会尽力回答。

**更新**：我原本在错误的部分列出了一些算法，如神经网络和朴素的贝叶斯，这让事情变得混乱。全部修复了。