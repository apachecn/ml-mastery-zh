# 深度学习字幕生成模型的温和介绍

> 原文： [https://machinelearningmastery.com/deep-learning-caption-generation-models/](https://machinelearningmastery.com/deep-learning-caption-generation-models/)

字幕生成是在给定照片的情况下生成人类可读的文本描述的具有挑战性的人工智能问题。

它需要来自计算机视觉领域的图像理解和来自自然语言处理领域的语言模型。

重要的是要考虑和测试多种方法来构建给定的预测建模问题，并且确实有很多方法来构建为照片生成字幕的问题。

在本教程中，您将发现 3 种可以构建字幕生成方式以及如何为每种方法开发模型的方法。

我们将看到的三个字幕生成模型是：

*   模型 1：生成整个序列
*   模型 2：从 Word 生成 Word
*   模型 3：从序列生成单词

我们还将回顾一些在准备数据和开发字幕生成模型时要考虑的最佳实践。

让我们开始吧。

## 模型 1：生成整个序列

第一种方法涉及为给定照片的照片生成整个文本描述。

*   **输入**：照片
*   **输出**：完整的文字说明。

这是一对多序列预测模型，以一次性方式生成整个输出。

![Model 1 - Generate Whole Sequence](img/10b0cd22ffb0fbceff19c128b2752e96.jpg)

模型 1 - 生成整个序列

该模型给语言模型带来了沉重的负担，以正确的顺序生成正确的单词。

照片通过特征提取模型，例如在 ImageNet 数据集上预先训练的模型。

一个热编码用于输出序列，允许模型预测整个词汇表中序列中每个单词的概率分布。

所有序列都填充到相同的长度。这意味着模型被迫在输出序列中生成多个“_ 无字 _”时间步长。

测试这种方法，我发现需要一个非常大的语言模型，即使这样，也很难超越生成 NLP 等效持久性的模型，例如：生成与整个序列长度重复的相同字作为输出。

## 模型 2：从 Word 生成 Word

这是一种不同的方法，其中 LSTM 生成给定照片和一个单词作为输入的一个单词的预测。

*   **输入 1** ：照片。
*   **输入 2** ：先前生成的单词或序列标记的开始。
*   **输出**：顺序的下一个字。

这是一对一序列预测模型，通过对模型的递归调用生成文本描述。

![Model 2- Generate Word From Word](img/efb412506f58e1ccdd0405086e39d711.jpg)

模型 2 - 从 Word 生成单词

单词输入是在第一次调用模型时指示序列开始的标记，或者是从上次调用模型时生成的单词。

照片通过特征提取模型，例如在 ImageNet 数据集上预先训练的模型。输入字是整数编码的，并通过字嵌入。

输出字是一个热编码，以允许模型预测整个词汇表中单词的概率。

重复递归字生成过程，直到生成序列标记的结束。

测试这个方法，我发现模型确实产生了一些好的 n-gram 序列，但是在一个循环中被捕获，重复相同的单词序列以进行长描述。模型中没有足够的内存来记住之前生成的内容。

## 模型 3：从序列生成单词

给定照片和已经为照片生成的一系列单词作为输入，预测描述中的下一个单词。

*   **输入 1** ：照片。
*   **输入 2** ：先前生成的单词序列，或序列标记的开始。
*   **输出**：顺序的下一个字。

这是一个多对一序列预测模型，通过对模型的递归调用生成文本描述。

![Model 3 - Generate Word From Sequence](img/a972f08e77f6fd0762eca0f5f01afe26.jpg)

模型 3 - 从序列生成单词

它是上述模型 2 的概括，其中单词的输入序列为模型提供了用于生成序列中的下一个单词的上下文。

照片通过特征提取模型，例如在 ImageNet 数据集上预先训练的模型。可以在每个时间步骤中提供照片，或者在开始时提供一次，这可能是优选的方法。

输入序列被填充为固定长度和整数编码以通过字嵌入。

输出字是一个热编码，以允许模型预测整个词汇表中单词的概率。

重复递归字生成过程，直到生成序列标记的结束。

这似乎是关于该主题的论文中描述的首选模型，并且可能是我们目前针对此类问题的最佳结构。

测试这种方法，我发现该模型很容易生成可读的描述，其质量通常由经过更长时间训练的大型模型改进。该模型技能的关键是屏蔽填充的输入序列。没有掩蔽，所产生的单词序列是可怕的，例如，序列标记的结束反复重复。

## 建模最佳实践

本节列出了开发字幕生成模型时的一些常规技巧。

*   **预训练的照片特征提取模型**。使用在 ImageNet 等大型数据集上预训练的照片特征提取模型。这称为转学习。 2014 年赢得 ImageNet 竞赛的牛津视觉几何组（VGG）模型是一个良好的开端。
*   **预训练的单词嵌入模型**。使用经过预先训练的单词嵌入模型，该模型使用平均大型语料库训练的向量或训练您的特定文本数据。
*   **Fine Tune 预训练模型**。探索在您的模型中训练预训练模型，看看它们是否可以针对您的特定问题进行拨入，并导致技能略有提升。
*   **预处理文本**。预处理文本描述以减少要生成的单词的词汇量，进而减少模型的大小。
*   **预处理照片**。预处理照片特征提取模型的照片，甚至预提取特征，以便在训练模型时不需要完整的特征提取模型。
*   **填充文字**。将输入序列填充到固定长度;这实际上是为深度学习库向量化输入的要求。
*   **掩蔽填充**。在嵌入层上使用掩码忽略“_ 无字 _”时间步长，当字是整数编码时通常为零值。
*   **注意**。在生成输出字时要注意输入序列，以便在生成每个字时获得更好的表现并理解模型“_ 看 _”的位置。
*   **评估**。使用标准文本翻译指标（如 BLEU）评估模型，并将生成的描述与多个参考图像标题进行比较。

您是否有自己的最佳实践来开发强大的字幕模型？
请在下面的评论中告诉我。

## 进一步阅读

如果您要深入了解，本节将提供有关该主题的更多资源。

*   [Show and Tell：神经图像标题生成器](https://arxiv.org/abs/1411.4555)，2015。
*   [显示，参与和讲述：视觉注意的神经图像标题生成](https://arxiv.org/abs/1502.03044)，2015。
*   [将图像放在图像标题生成器](https://arxiv.org/abs/1703.09137)中的位置，2017。
*   [图像自动生成描述：模型，数据集和评估措施的调查](https://www.jair.org/media/4900/live-4900-9139-jair.pdf)，2016。

## 摘要

在本教程中，您发现了 3 个序列预测模型，可用于解决为照片生成人类可读文本描述的问题。

你有没有尝试过这些模型？
在下面的评论中分享您的经历。

你有任何问题吗？
在下面的评论中提出您的问题，我会尽力回答。