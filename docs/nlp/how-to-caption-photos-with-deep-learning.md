# 如何利用深度学习自动生成照片的文本描述

> 原文： [https://machinelearningmastery.com/how-to-caption-photos-with-deep-learning/](https://machinelearningmastery.com/how-to-caption-photos-with-deep-learning/)

字幕图像涉及在给定图像（例如照片）的情况下生成人类可读的文本描述。

这对于人来说是一个简单的问题，但对机器来说非常具有挑战性，因为它既涉及理解图像的内容，又涉及如何将这种理解转化为自然语言。

最近，深度学习方法取代了传统方法，并且为图像自动生成描述（称为“字幕”）的问题实现了最先进的结果。

在这篇文章中，您将了解如何使用深度神经网络模型自动生成图像描述，例如照片。

完成这篇文章后，你会知道：

*   关于为图像生成文本描述的挑战以及结合计算机视觉和自然语言处理的突破的需要。
*   关于构成神经特征字幕模型的元素，即特征提取器和语言模型。
*   如何使用注意机制将模型的元素排列到编解码器中。

让我们开始吧。

## 概观

这篇文章分为 3 部分;他们是：

1.  用文本描述图像
2.  神经字幕模型
3.  编解码器架构

## 用文本描述图像

描述图像是生成图像的人类可读文本描述的问题，例如对象或场景的照片。

该问题有时被称为“_ 自动图像注释 _”或“_ 图像标记 _”。

对于人来说这是一个简单的问题，但对于机器来说却非常具有挑战性。

> 快速浏览图像就足以让人指出并描述有关视觉场景的大量细节。然而，这种卓越的能力已被证明是我们视觉识别模型的一项难以捉摸的任务

- [用于生成图像描述的深度视觉语义对齐](https://arxiv.org/abs/1412.2306)，2015。

解决方案需要理解图像的内容并将其翻译成单词的含义，并且单词必须串在一起才能被理解。它结合了计算机视觉和自然语言处理，在更广泛的人工智能中标志着一个真正的挑战性问题

> 自动描述图像的内容是连接计算机视觉和自然语言处理的人工智能中的基本问题。

- [Show and Tell：神经图像标题生成器](https://arxiv.org/abs/1411.4555)，2015。

此外，问题可能存在困难;让我们看一下示例中问题的三种不同变化。

### 1.分类图像

为图像分配来自数百或数千个已知类之一的类标签。

![Example of classifying images into known classes](img/e8fedb2abc9ff288281994e19c378e2b.jpg)

将图像分类为已知类的示例
摘自“检测鳄梨到西葫芦：我们做了什么，我们要去哪里？”，2013 年。

### 2.描述图像

生成内容图像的文本描述。

![Example of captions generated for photogaphs](img/bbefe3affc12f1fe2a508c6e6ea158ca.jpg)

为 photogaphs 生成的字幕示例
取自“用于视觉识别和描述的长期复发卷积网络”，2015 年。

### 3.注释图像

为图像上的特定区域生成文本描述。

![Example of annotation regions of an image with descriptions](img/00257adfd720b362b3e2733b9a176c05.jpg)

具有描述的图像的注释区域的示例。
取自“用于生成图像描述的深度视觉语义对齐”，2015 年。

一般问题也可以扩展到在视频中随时间描述图像。

在这篇文章中，我们将把注意力集中在描述图像上，我们将其描述为'_ 图像字幕 _。

## 神经字幕模型

神经网络模型已经成为自动字幕生成领域的主导;这主要是因为这些方法展示了最先进的结果。

在用于生成图像标题的端到端神经网络模型之前的两种主要方法是基于模板的方法和基于最近邻居的方法以及修改现有标题。

> 在使用神经网络生成字幕之前，两种主要方法占主导地位。第一个涉及生成标题模板，这些模板根据对象检测和属性发现的结果填写。第二种方法基于首先从大型数据库中检索类似的字幕图像，然后修改这些检索到的字幕以适合查询。 [...]这两种方法都已经不再支持现在占主导地位的神经网络方法。

- [显示，参与和讲述：视觉注意的神经图像标题生成](https://arxiv.org/abs/1502.03044)，2015。

用于字幕的神经网络模型涉及两个主要元素：

1.  特征提取。
2.  语言模型。

### 特征提取模型

特征提取模型是神经网络，其给定图像能够提取显着特征，通常以固定长度向量的形式。

提取的特征是图像的内部表示，而不是直接可理解的东西。

深度卷积神经网络或 CNN 用作特征提取子模型。可以直接在图像字幕数据集中的图像上训练该网络。

或者，可以使用预训练的模型，例如用于图像分类的现有技术模型，或者使用预先训练的模型并对问题进行微调的一些混合模型。

在为 ILSVRC 挑战开发的 ImageNet 数据集中使用表现最佳的模型很受欢迎，例如 Oxford Vision Geometry Group 模型，简称为 VGG。

> [...]我们探索了几种处理过拟合的技术。不过拟合的最明显的方法是将我们系统的 CNN 组件的权重初始化为预训练模型（例如，在 ImageNet 上）

- [显示，参与和讲述：视觉注意的神经图像标题生成](https://arxiv.org/abs/1502.03044)，2015。

![Feature Extractor](img/df92f91870144ab9724c30295efa7685.jpg)

特征提取器

### 语言模型

通常，语言模型在给定已经存在于序列中的单词的情况下预测序列中下一个单词的概率。

对于图像字幕，语言模型是一种神经网络，给定从网络中提取的特征能够预测描述中的单词序列，并以已经生成的单词为条件建立描述。

使用循环神经网络（例如长短期记忆网络或 LSTM）作为语言模型是很流行的。每个输出时间步骤在序列中生成一个新单词。

然后使用字嵌入（例如 word2vec）对生成的每个字进行编码，并将其作为输入传递给解码器以生成后续字。

对模型的改进涉及在输出序列的词汇表中收集单词的概率分布并搜索它以生成多个可能的描述。可以对这些描述进行评分并按可能性排序。通常使用 Beam Search 进行此搜索。

可以使用从图像数据集中提取的预先计算的特征来独立地训练语言模型;它可以与特征提取网络或某种组合共同训练。

![Language Model](img/69dfe5e8f735119e0e47ea955bbd8c3e.jpg)

语言模型

## 编解码器架构

构建子模型的流行方法是使用编解码器架构，其中两个模型被联合训练。

> [该模型]基于卷积神经网络，该网络将图像编码为紧凑表示，然后是生成相应句子的循环神经网络。训练该模型以最大化给定图像的句子的可能性。

- [Show and Tell：神经图像标题生成器](https://arxiv.org/abs/1411.4555)，2015。

这是为机器翻译开发的架构，其中输入序列（例如法语）由编码器网络编码为固定长度向量。然后，一个单独的解码器网络读取编码并以新语言生成输出序列，比如英语。

除了该方法令人印象深刻的技能之外，这种方法的好处是可以针对该问题训练单个端到端模型。

当适用于图像字幕时，编码器网络是深度卷积神经网络，并且解码器网络是 LSTM 层的栈。

> [机器翻译]“编码器”RNN 读取源句子并将其转换为富的固定长度向量表示，其又用作生成目标句子的“解码器”RNN 的初始隐藏状态。在这里，我们建议遵循这个优雅的秘籍，用深度卷积神经网络（CNN）代替编码器 RNN。

- [Show and Tell：神经图像标题生成器](https://arxiv.org/abs/1411.4555)，2015。

![Example of the CNN and LSTM Architecture](img/69e5b4673f02fec1116478202afcb95e.jpg)

CNN 和 LSTM 架构的示例。
取自“Show and Tell：A Neural Image Caption Generator”，2015。

### 带注意的字幕模型

编解码器架构的限制是使用单个固定长度表示来保持提取的特征。

通过在更丰富的编码中开发注意力在机器翻译中解决了这一问题，允许解码器在生成翻译中的每个单词时学习在何处注意。

通过允许解码器在描述中生成每个单词时学习将注意力放在图像中的哪个位置，已经使用关注方法来改进用于图像字幕的编解码器架构的表现。

> 最近在字幕生成方面的进步以及最近在机器翻译和对象识别中引起注意力的成功激发了我们的鼓舞，我们研究了可以在生成其标题时关注图像的显着部分的模型。

- [显示，参与和讲述：视觉注意的神经图像标题生成](https://arxiv.org/abs/1502.03044)，2015。

这种方法的一个好处是可以在描述中生成每个单词时准确地可视化注意的位置。

> 我们还通过可视化显示模型如何能够在输出序列中生成相应的单词时自动学习如何将注视固定在显着对象上。

- [显示，参与和讲述：视觉注意的神经图像标题生成](https://arxiv.org/abs/1502.03044)，2015。

用一个例子来说这是最容易理解的;见下文。

![Example of image captioning with attention](img/d387687b7fbb194b8fd85be888373fb8.jpg)

注意图像字幕的示例
取自“显示，参加和讲述：视觉注意的神经图像标题生成”，2015 年。

## 进一步阅读

如果您要深入了解，本节将提供有关该主题的更多资源。

### 文件

*   [Show and Tell：神经图像标题生成器](https://arxiv.org/abs/1411.4555)，2015。
*   [显示，参与和讲述：视觉注意的神经图像标题生成](https://arxiv.org/abs/1502.03044)，2015。
*   [用于视觉识别和描述的长期复发卷积网络](https://arxiv.org/abs/1411.4389)，2015。
*   [用于生成图像描述的深层视觉语义对齐](https://arxiv.org/abs/1412.2306)，2015。

### 用品

*   [维基百科上的自动图像注释](https://en.wikipedia.org/wiki/Automatic_image_annotation)
*   [Show and Tell：图片字幕开源于 TensorFlow](https://research.googleblog.com/2016/09/show-and-tell-image-captioning-open.html) ，2016 年。
*   [演示：使用 ConvNets 和 Recurrent Nets](https://www.youtube.com/watch?v=xKt21ucdBY0) ，Andrej Karpathy 和 Fei-Fei Li（[幻灯片](https://cs.stanford.edu/people/karpathy/sfmltalk.pdf)）进行自动图像捕获。

### 项目

*   [项目：用于生成图像描述的深层视觉语义对齐](http://cs.stanford.edu/people/karpathy/deepimagesent/)，2015。
*   [NeuralTalk2：Torch 中的高效图像字幕代码，运行在 GPU](https://github.com/karpathy/neuraltalk2) ，Andrej Karpathy 上。

## 摘要

在这篇文章中，您发现了如何使用深度神经网络模型自动生成图像描述，例如照片。

具体来说，你学到了：

*   关于为图像生成文本描述的挑战以及结合计算机视觉和自然语言处理的突破的需要。
*   关于构成神经特征字幕模型的元素，即特征提取器和语言模型。
*   如何使用注意机制将模型的元素排列到编解码器中。

你有任何问题吗？
在下面的评论中提出您的问题，我会尽力回答。